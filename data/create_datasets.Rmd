---
title: "Biobank (you need at least 32GB memory to run this)"
output: md_document
---

# init
```{r}
#load data
library(ampvis2)
library(openxlsx)
library(data.table)
library(tidyverse)
# need at least data.table version 1.14.99 to allow writing files with encoding
if (packageVersion("data.table") < "1.14.99") {
  stop("data.table must be version 1.14.99 or later. Upgrade with \"data.table::update_dev_pkg()\" or \"install.packages('data.table', repos='https://rdatatable.gitlab.io/data.table', ref = '1.14.99')\" if it's not available on CRAN for your R version.")
}

if (interactive()) {
  if (!grepl("data$", getwd())) {
    setwd("data")
  }
}
```

This markdown filters samples, makes sure sample metadata is correct, and splits the data into one dataset per WWTP.

# Load metadata
```{r}
rm(list=ls())
gc()
metadata <- fread("amplicon_data/biobank/metadata.txt", encoding = "Latin-1")

if (any(duplicated(metadata$Sample))) {
  stop("One or more sample name(s) are duplicated in sample metadata. Please fix manually")
}

#filter a few useless samples
metadata <- filter(metadata, !Sample %chin% paste0("MQ201110-", 309:311))
metadata$Date <- lubridate::dmy(metadata$Date)
metadata$Year <- as.character(lubridate::year(metadata$Date))

#### add seasonal period and week number ####
#extract seasonal periods from dates
WS <- as.Date("2012-12-15", format = "%Y-%m-%d") # Winter Solstice
SE <- as.Date("2012-3-15",  format = "%Y-%m-%d") # Spring Equinox
SS <- as.Date("2012-6-15",  format = "%Y-%m-%d") # Summer Solstice
FE <- as.Date("2012-9-15",  format = "%Y-%m-%d") # Fall Equinox

# Convert dates from any year to 2012 dates
dates <- as.Date(strftime(metadata$Date, format = "2012-%m-%d"))
#extract periods and set factors for correct chronological order
metadata$Period <- ifelse (
  dates >= WS | dates < SE, "Winter", #winter
    ifelse (dates >= SE & dates < SS, "Spring", #spring
      ifelse (dates >= SS & dates < FE, "Summer", "Fall") #summer, fall
    )
  )
metadata$Period <- factor(
  metadata$Period,
  levels = c("Spring", "Summer", "Fall", "Winter")
)

metadata <- tibble::add_column(
  metadata,
  Week = as.character(lubridate::isoweek(metadata$Date)),
  .after = "Date"
)

setDT(metadata)
#### fix Plant and ID columns ####
# controls
metadata[grepl("extneg", tolower(LibID)), ID := "EXTNEG"]
metadata[grepl("extneg", tolower(LibID)), Plant := "CTRL"]
metadata[grepl("pcrpor", tolower(LibID)), ID := "PCRPOS"]
metadata[grepl("pcrpos", tolower(LibID)), Plant := "CTRL"]
metadata[grepl("pcrneg", tolower(LibID)), ID := "PCRNEG"]
metadata[grepl("pcrneg", tolower(LibID)), Plant := "CTRL"]
metadata <- metadata[!is.na(Plant)] #this removes the weird LibID samples: MQ181023-148, MQ181203-218, MQ181214-138, MQ190919-270
metadata <- metadata[!Sample %chin% "MQ201110-248"]
metadata[Plant == "Avedoere", Plant := "Avedøre"]
metadata[Plant == "Damhusaaen", Plant := "Damhusåen"]
metadata[Plant == "Ejby Moelle", Plant := "Ejby Mølle"]
metadata[Plant == "Hjoerring", Plant := "Hjørring"]
metadata[Plant == "Naestved", Plant := "Næstved"]
metadata[Plant == "Egaa", Plant := "Egå"]
metadata[grepl("^Dam", ID) & !grepl("CTRL", Plant), Plant := paste0("Damhusåen-", Line)]
metadata[Plant %chin% "Damhusåen", Plant := paste0("Damhusåen-", Line)]
metadata[ID == "Lynetten", Plant := "Lynetten"]
metadata[ID == "Avedøre", Plant := "Avedøre"]
#metadata[is.na(Plant) & is.na(Line), Plant := ID]


#make sure date column is parsed correctly (year-month-day prefered) and
#sort chronologically, abundances will be sorted according to metadata by amp_load
metadata <- arrange(metadata, Plant, Date)
```

# merge Aalborg West+East temperatures (by weekly average) with metadata
```{r}
# Aalborg East
AAEtemps <- data.table::fread("metadata/AalborgEastTemperatures.csv")
colnames(AAEtemps) <- c("DateTime.Temperature", "Temperature")
AAEtemps <- AAEtemps[!is.na(DateTime.Temperature) & !is.na(Temperature)] #filter empty ones
AAEtemps[,DateTime.Temperature := lubridate::mdy_hm(DateTime.Temperature)] #parse dates
AAEtemps[,DateTime.Temperature := lubridate::floor_date(DateTime.Temperature, unit = "day")] #floor to day (remove HM)
AAEtemps[,Year := as.character(lubridate::year(DateTime.Temperature))] #extract year
AAEtemps[,Week := as.character(lubridate::isoweek(DateTime.Temperature))] #extract week (ISO standard)
AAEtemps[,DateTime.Temperature := as.character(DateTime.Temperature)] #coerce back to character
AAEtemps <- AAEtemps[,.(week_mean_temperature = mean(Temperature)),keyby=.(Year, Week)] #sometimes multiple measurements per week
AAEtemps[,Plant := "Aalborg E"]

# Aalborg West
AAWtemps <- data.table::fread("metadata/AalborgWestTemperatures.csv")
colnames(AAWtemps) <- c("DateTime.Temperature", "Temperature")
AAWtemps <- AAWtemps[!is.na(DateTime.Temperature) & !is.na(Temperature)] #filter empty ones
AAWtemps[,DateTime.Temperature := lubridate::mdy_hm(DateTime.Temperature)] #parse dates
AAWtemps[,DateTime.Temperature := lubridate::floor_date(DateTime.Temperature, unit = "day")] #floor to day (remove HM)
AAWtemps[,Year := as.character(lubridate::year(DateTime.Temperature))] #extract year
AAWtemps[,Week := as.character(lubridate::isoweek(DateTime.Temperature))] #extract week (ISO standard)
AAWtemps[,DateTime.Temperature := as.character(DateTime.Temperature)] #coerce back to character
AAWtemps <- AAWtemps[,.(week_mean_temperature = mean(Temperature)),keyby=.(Year, Week)] #sometimes multiple measurements per week
AAWtemps[,Plant := "Aalborg W"]

temps <- data.table::rbindlist(list(AAEtemps, AAWtemps))

metadata_merged <- dplyr::left_join(
  metadata,
  temps,
  by = c("Plant", "Year", "Week")
)
metadata_out <- dplyr::filter(
  metadata_merged,
  !Plant %chin% c("EXTNEG", "PCRPOS", "PCRNEG", "", "CTRL"),
  !Line %chin% c("HC-O", "HC-U")
)
data.table::fwrite(metadata_out, "metadata.csv")
```

# load amplicon data
```{r load_data}
d <- amp_load(
  otutable = "amplicon_data/biobank/ASVtable_midas481.zip",
  metadata = metadata_out
)
```

# remove samples with few reads, and normalise reads to sample total
```{r normalise}
ds <- d %>%
  amp_subset_samples(minreads = 5000, removeAbsents = TRUE, normalise = TRUE) # 1000 removes 117 samples, 5000 removes 210 samples
gc()
datasets <- c(
  "Aalborg E"
  ,"Aalborg W"
  ,"Avedøre"
  #,"Bjergmarken" #<- too short
  #,"Damhusåen-" #<- error in metadata
  ,"Damhusåen-A"
  ,"Damhusåen-B"
  ,"Damhusåen-C"
  ,"Damhusåen-D"
  ,"Egå"
  ,"Ejby Mølle"
  ,"Esbjerg E"
  ,"Esbjerg W"
  ,"Fredericia" #<- industrial plant
  ,"Haderslev"
  ,"Hirtshals"
  ,"Hjørring"
  ,"Kalundborg" #<- industrial plant
  ,"Lynetten" #<- maybe too short
  ,"Mariagerfjord"
  #,"Marselisborg" #<- too short
  #,"Marselisborg_DEMON" #<- too short
  #,"Marselisborg_DEMON_V4" #<- too short
  #,"Marselisborg_V4" #<- too short
  #,"Næstved" #<- contains a sampling pause for 2 years
  ,"Odense NE"
  ,"Odense NV"
  ,"Randers"
  ,"Ribe"
  ,"Viborg"
  ,"Viby"
)
```

# Select and create data subsets
```{r export_datasets, eval = TRUE}
datasets_list <- lapply(datasets, function(wwtp) { #for (wwtp in datasets) {
  print(wwtp)
  #filter
  dataset <- amp_subset_samples(
    ds,
    Plant %in% wwtp,
    normalise = FALSE
  ) %>%
    filter_otus(0.1)

  dataset_folder <- file.path("datasets", wwtp)
  dir.create(dataset_folder, recursive = TRUE, showWarnings = FALSE)

  #write out abundance table
  fwrite(
    data.table(
      ASV = rownames(dataset$abund),
      dataset$abund
    ),
    file = file.path(dataset_folder, "ASVtable.csv")
  )

  #write out taxonomy
  fwrite(
    dataset$tax,
    file = file.path(dataset_folder, "taxonomy.csv")
  )

  #write out metadata
  fwrite(
    dataset$metadata,
    bom = TRUE,
    encoding = "UTF-8",
    file = file.path(dataset_folder, "metadata.csv")
  )
  
  return(dataset)
})

# what's the median rel abundance of the least abundant ASV of the top 200 most abundant ASVs for each dataset?
sapply(
  datasets_list,
  function(dataset) {
    apply(dataset[["abund"]][names(sort(rowSums(dataset[["abund"]]), decreasing = TRUE)[200]),],1, median)
  }
) %>% fivenum
```

# overview of samples over time (all)
```{r samples_overview_all, fig.width = 12, fig.height = 8}
m <- data.table(ds$metadata)
m[, used := ifelse(Plant %chin% datasets, "used", "not used")]

#append number of samples to plant/dataset names
m[, nsamples_plant := .N, by = Plant]
m[, Plant := paste0(Plant, " (", nsamples_plant, " samples)")]

#order datasets by the number of samples (extracted from dataset names)
nsamples <- m[,unique(Plant)] %>%
  #extract pattern: (123 samples)
  stringi::stri_extract_all_regex(
    "\\([0-9]+ samples\\)$"
  ) %>%
  #extract pattern: 0-9
  stringi::stri_extract_all_regex(
    "[0-9]+"
  ) %>%
  as.numeric
plants_ordered <- m[,unique(Plant)][order(nsamples, decreasing = TRUE)]
m[,Plant := factor(Plant, levels = plants_ordered)]

samples_overview_all <- ggplot(
  m,
  aes(x = Date,
      y = Plant,
      color = used)) +
  geom_point() +
  scale_x_date(date_breaks = "year", date_labels = "%Y") +
  scale_color_manual(values = RColorBrewer::brewer.pal(3, "Set1")[c(1, 3)]) +
  theme(
    axis.title = element_blank(),
    axis.text.x = element_text(angle = 90))

ggsave("samples_overview_all.png", plot = samples_overview_all)
```

# overview of samples over time (only those selected for the paper)
```{r samples_overview, fig.width = 12, fig.height = 8}
samples_overview <- ggplot(m[used == "used"], aes(Date, Plant)) +
  geom_point() +
  scale_x_date(date_breaks = "year", date_labels = "%Y") +
  theme(
    axis.title = element_blank(),
    axis.text.x = element_text(angle = 90))
ggsave("samples_overview_used.png", plot = samples_overview)
```

# Overview of sampling intervals
```{r sampling_intervals}
sampling_intervals <- ggplot(
  m[
    used == "used",
    .(duration = .SD[!duplicated(Date), as.numeric(diff(sort(Date)))]),
    by = Plant
  ],
  aes(duration, Plant)
) +
  geom_boxplot() +
  theme(axis.title.y = element_blank()) +
  xlab("Sampling interval (days)") +
  scale_x_continuous(trans = "sqrt", breaks = c(1,7,14,21,28,90))
ggsave("sampling_intervals.png", plot = sampling_intervals)
```
